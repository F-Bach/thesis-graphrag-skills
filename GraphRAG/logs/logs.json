{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Aya | Experience: devops_engineer: 4 years, backend_developer: 2 years, marketing_manager: 4 years, project_manager: 5 years | Languages: English B2, Spanish Native | Technical Skills: AI Model Deployment, Azure DevOps, Azure AI, Azure, Azure Kubernetes Service, Docker, HashiCorp Nomad, Kubernetes, Pulumi, Terraform | Programming Languages: Python, Shell | Programming Language Packages: FastAPI (Python), Flask (Python), NumPy (Python), Pytest (Python), Pygame (Python), Scrapy (Python), Oh My Zsh (Shell)"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Mikel | Experience: software_engineer: 2 years, business_intelligence: 1 year, supply_chain_management: 3 years | Languages: Spanish Native, Galician Native, English B2 | Education: Bachelor of Civil Engineering, Master of Logistics and International Trade | Technical Skills: MongoDB, PostgreSQL, Azure, Git | Programming Languages: JavaScript, Python, TypeScript | Programming Language Packages: Chart.js (JavaScript), Jest (JavaScript), Lodash (JavaScript), Meteor (JavaScript), Moment.js (JavaScript), Next.js (JavaScript), Node.js (JavaScript), React (JavaScript), Redux (JavaScript), RxJS (JavaScript), Vue.js (JavaScript), Webpack (JavaScript), Zustand (JavaScript), Express (JavaScript), FastAPI (Python), Pytest (Python), GraphQL (TypeScript), Formik (TypeScript), Joi (TypeScript), Material-UI (TypeScript), NestJS (TypeScript), Next.js (TypeScript), React (TypeScript), React Hook Form (TypeScript), TypeORM (TypeScript), ts-jest (TypeScript), Vue.js (TypeScript)"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Jesus | Experience: senior_consultant: 8 years | Languages: English A1 | Technical Skills: Azure | Programming Languages: C#, JavaScript, TypeScript | Programming Language Packages: AutoMapper (C#), ASP.NET (C#), Entity Framework (C#), Dapper (C#), FluentValidation (C#), NLog (C#), JQuery (JavaScript), Node.js (JavaScript), Angular (TypeScript)"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Nahia | Experience: data_engineer: 2 years | Languages: Spanish Native, English C1, Catalan Native, German A1 | Education: Bachelor of Data Engineering, Master of Big Data & Analytics | Technical Skills: Apache Hadoop, Apache Spark, AWS, AWS CloudFormation, AWS Glue, AWS Lambda, AWS S3, AWS SageMaker, Azure, Azure Data Factory, Azure DevOps, Data Lake, Data Mesh, DataBricks, Delta Lake, Deep Learning, Docker, Iceberg, Jupyter Notebooks, MongoDB, Spark, Time Series Forecasting, Neural Networks | Programming Languages: Python, R | Programming Language Packages: Cython (Python), Flask (Python), Jupyter (Python), Matplotlib (Python), NumPy (Python), OpenCV (Python), Pandas (Python), Plotly (Python), PySpark (Python), PyTorch (Python), Scikit-learn (Python), Scikit-image (Python), Seaborn (Python), TensorFlow (Python), Tkinter (Python), XGBoost (Python), dplyr (R), ggplot2 (R), plotly (R), RMarkdown (R)"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Liam | Experience: backend_and_devops_engineer: 1 year, full_stack_engineer: 3 years | Languages: Spanish Native, English C1, German A1 | Education: Bachelor of Computer Engineering | Technical Skills: AI Agents, Terraform, LLMs, Google Cloud Run, Google Cloud Functions, Gen AI, Docker, DataBricks, Azure Functions, Azure AI, Azure, Full-Stack Development, Backend Development, API Development, Google Cloud Platform, Git, DevOps, DevSecOps, REST APIs, Infrastructure as Code | Programming Languages: Python, TypeScript, JavaScript | Programming Language Packages: Django (Python), FastAPI (Python), Flask (Python), Jupyter (Python), Pandas (Python), Pytest (Python), Pytest-django (Python), Pytest-flask (Python), Requests (Python), SQLAlchemy (Python), Pydantic (Python), GraphQL (TypeScript), Vue.js (TypeScript), React (TypeScript), Vue.js (JavaScript), Node.js (JavaScript), React (JavaScript)"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Nuria | Experience: service_manager: 11 years, big_data_engineer: 6 years, functional_analyst: 19 years | Languages: English B2, Spanish Native | Education: Bachelor of Physics, Master of Information and Communication Systems Management, Master of Big Data and Business Analytics | Technical Skills: SQL, Phyton, Data Lake, Delta Lake, Jupyter Notebooks, Azure, DataBricks, Spark, PowerBI, Mainframe | Programming Languages: Python, Bash, Cobol, Pyspark, R | Programming Language Packages:"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 1 column 1788 (char 1787)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Arturo | Experience: data_engineer: 2 years | Languages: Spanish Native, English C1, Catalan Native, German A1 | Education: Bachelor of Data Engineering, Master of Big Data & Analytics | Technical Skills: Apache Hadoop, Apache Spark, AWS, AWS CloudFormation, AWS Glue, AWS Lambda, AWS S3, AWS SageMaker, Azure, Azure Data Factory, Azure DevOps, Data Lake, Data Mesh, DataBricks, Delta Lake, Deep Learning, Docker, Iceberg, Jupyter Notebooks, MongoDB, Spark, Time Series Forecasting, Neural Networks, Synthetic Data Generation | Programming Languages: Python, R | Programming Language Packages: Cython (Python), Jupyter (Python), Matplotlib (Python), NumPy (Python), OpenCV (Python), Pandas (Python), Plotly (Python), PySpark (Python), PyTorch (Python), Scikit-learn (Python), Scikit-image (Python), Seaborn (Python), TensorFlow (Python), Tkinter (Python), XGBoost (Python), dplyr (R), ggplot2 (R), plotly (R), RMarkdown (R)"
    }
}
{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 29, in get\n    data = json.loads(data)\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 283, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 107, in invoke\n    cached = await self._cache.get(key)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\cache.py\", line 25, in get\n    return await self._cache.get(key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\cache\\json_pipeline_cache.py\", line 34, in get\n    await self._storage.delete(key)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPermissionError: [WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'\n",
    "source": "[WinError 32] El proceso no tiene acceso al archivo porque est치 siendo utilizado por otro proceso: 'C:\\\\Users\\\\fbachpa\\\\Documents\\\\Graphiculum\\\\GraphRAG final\\\\cache\\\\extract_graph\\\\chat_extract-continuation-0_e741f47afb5c01e85b0a66374ed4f2efb7e7f8f1b75572dd73593a02c83286f0_v2'",
    "details": {
        "doc_index": 0,
        "text": "Name: Martin | Experience: machine_learning_engineer: 5 years, data_engineer: 2 years | Languages: Spanish Native, English C1 | Education: Bachelor of Computer Engineering, Master of Data Science and Engineering | Technical Skills: AI Agents, AI Governance, AI Model Deployment, AI Model Monitoring, AI Safety, AI Security, Apache Hadoop, Apache Kafka, Apache Spark, AWS, Azure, Azure AI, Azure Machine Learning, CNN, CloudStack, Computer Vision, Data Augmentation, DataBricks, Deep Learning, Docker, Embeddings, Fine-tuning, GAN, Gen AI, Google Cloud Functions, Graph Neural Networks, Hyperparameter Tuning, Image Classification, Jupyter Notebooks, Kafka, Knowledge Graphs, LangChain, Language Models, LLMs, LSTM, MongoDB, Neo4j, Neural Networks, NLP, OCR, Prompt Engineering, RAG, Reinforcement Learning, Sentiment Analysis, Splunk, Spark, SQL Optimization, Text Processing, Time Series Forecasting, Transformers, Transfer Learning, Streamlit, MLFlow, Redis, Databases, OracleSQL, Big Data Systems, API, AI  systems architecture, Linux, NoSQL, Cloud Environments, Cloud Deployment, Data analysis, Data visualization, AI Fairness | Programming Languages: C, C++, Java, JavaScript, MATLAB, Python, R, Shell | Programming Language Packages: Angular (JavaScript), React (JavaScript)"
    }
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 77, in invoke\n    return await this.invoke_json(delegate, prompt, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 96, in invoke_json\n    return await self.try_receive_json(delegate, prompt, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 112, in try_receive_json\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 115, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\services\\rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_text_chat_llm.py\", line 157, in _execute_llm\n    completion = await self._client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1742, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py\", line 1484, in request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 103, in handle_async_request\n    return await self._connection.handle_async_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 136, in handle_async_request\n    raise exc\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 106, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 177, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 217, in _receive_event\n    data = await self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n    return await self._stream.receive(max_bytes=max_bytes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 204, in receive\n    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 147, in _call_sslobject_method\n    data = await self.transport_stream.receive()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1246, in receive\n    await self._protocol.read_event.wait()\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\locks.py\", line 213, in wait\n    await fut\nasyncio.exceptions.CancelledError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\index\\operations\\summarize_communities\\community_reports_extractor.py\", line 80, in __call__\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 281, in achat\n    response = await self.model(prompt, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 148, in __call__\n    await self._events.on_error(\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\events.py\", line 26, in on_error\n    self._on_error(error, traceback, arguments)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\utils.py\", line 45, in on_error\n    callbacks.error(\"Error Invoking LLM\", error, stack, details)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\callbacks\\workflow_callbacks_manager.py\", line 64, in error\n    callback.error(message, cause, stack, details)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\graphrag\\callbacks\\file_workflow_callbacks.py\", line 37, in error\n    json.dumps(\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py\", line 202, in encode\n    chunks = list(chunks)\n             ^^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py\", line 432, in _iterencode\n    yield from _iterencode_dict(o, _current_indent_level)\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py\", line 439, in _iterencode\n    o = _default(o)\n        ^^^^^^^^^^^\n  File \"C:\\Users\\fbachpa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py\", line 180, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\nTypeError: Object of type ModelMetaclass is not JSON serializable\n",
    "source": "Object of type ModelMetaclass is not JSON serializable",
    "details": null
}
